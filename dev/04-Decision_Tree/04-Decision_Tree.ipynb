{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Decision Trees\n",
    "\n",
    "The goal of this exercise is to to develop an understanding how to implement a decision tree.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "To solve this notebook you need the knowledge from the previous notebook. If you have problems solving it, take another look at the last week's notebooks.\n",
    "    \n",
    "It's also recommended to read the chapter 7 of the book in advance.\n",
    "</div>\n",
    "\n",
    "**Task**: In this exercise, we use a popular dataset to predict, if a patient has a heart disease or not, depending on some medical measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell two import the following modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\" align=\"left\">Load and preprocess data</h2>\n",
    "\n",
    "In the first step, we need to load the dataset. If your are interessted about the meaning of each feature, you can have a look at the description on the [UCI site](https://archive.ics.uci.edu/ml/datasets/statlog+(heart)) to this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset/heart.dat', delim_whitespace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(dataset, alpha=0.2, figsize=(12,12));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is complete and has only numerical values, we can do the train-test-split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = dataset.drop('target', axis=1)\n",
    "y = dataset['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=dataset['target'])\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Decision trees and ensemble methods, like random forests, do not require feature scaling to be performed as they are not sensitive to the the variance in the data.\n",
    "</div>\n",
    "\n",
    "<h2 style=\"color:blue\" align=\"left\">Build and evaluate the tree</h2>\n",
    "\n",
    "Now, that we have prepared the data, we can start to grow the tree. Therefore we use the built-in class `DecisionTreeClassifier` of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Task</b><br> \n",
    "Create an instance of a DecisionTreeClassifer and save it in the variable tree_clf. Then fit the model using the training data set. Set the parameter random_state to 42, to have comparable results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = None\n",
    "# Write Your Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the function defined below to visualize the full grown tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "def plot_decision_tree(dec_tree, feature_names, class_names, filename=None):\n",
    "    # Setting dpi = 300 to make image clearer than default\n",
    "    # fig size depends on the size of the tree\n",
    "    depth = dec_tree.tree_.max_depth\n",
    "    fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (depth*2,depth*2), dpi=300)\n",
    "    tree.plot_tree(dec_tree,\n",
    "               feature_names = feature_names, \n",
    "               class_names=class_names,\n",
    "               filled = True);\n",
    "    if filename != None:\n",
    "        fig.savefig(str(filename) + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Task</b><br> \n",
    "Use the function plot_decision_tree() to plot the tree you created in the previous task. If the output is too small, you can pass the function a filename as fourth parameter, to save the figure as png in the current directory.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=X.columns\n",
    "class_names=['no heart attack', 'heart attack']\n",
    "# Write Your Code Here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Task</b><br> \n",
    "Use the metrics Confusion Matrix and Accuracy score to evalute the performance of your model. Evaluate the model with the training and the test set. How do you assess the results?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Your Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Assess The Model Here_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\" align=\"left\">Regularization</h2>\n",
    "\n",
    "Especially if the model tends to overfitting, then the influence of max_depth and ccp_alpha should be examined.\n",
    "\n",
    "### Max depth\n",
    "\n",
    "Max_depth regulates the maximum depth of the tree.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Task</b><br> \n",
    "Use a for loop to create multiple trees with different depths. The values for max_depth to be examined are in the variable max_depths. Store the accuracy score of the training set and the test set in the variables provided. Then use the code in the next cell to visualize the results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "max_depths = range(1, tree_clf.tree_.max_depth+1)\n",
    "# Write Your Code Here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracies vs. max depth\n",
    "plt.plot(max_depths, train_accuracies, marker='o', label='Train Accuracy', drawstyle='steps-post')\n",
    "plt.plot(max_depths, test_accuracies, marker='o', label='Test Accuracy', drawstyle='steps-post')\n",
    "plt.title('Accuracies of regularised Decision Tree depeding on max depth')\n",
    "plt.xlabel('Max depth')\n",
    "plt.ylabel('Accuracy')\n",
    "#plt.ylim([0,1])\n",
    "#plt.axhline(y=1, color='black', linestyle='-')\n",
    "plt.legend(loc='lower right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning\n",
    "\n",
    "Another way to regularize a tree is the parameter ccp_alpha. With this parameter you can control the use of pruning. The higher the ccp_alpha value, the more batches will be pruned. \n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Task</b><br> \n",
    "Use a for loop to create multiple trees with different depths. The values for ccp_alpha to be examined are in the variable ccp_alphas. Store the accuracy score of the training set and the test set in the variables provided. Then use the code in the next cell to visualize the results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "ccp_alphas = np.linspace(0,0.1,11)\n",
    "# Write Your Code Here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracies vs. Alpha\n",
    "plt.plot(ccp_alphas, train_accuracies, marker='o', label=\"Train Accuracy\", drawstyle=\"steps-post\")\n",
    "plt.plot(ccp_alphas, test_accuracies, marker='o', label=\"Test Accuracy\", drawstyle=\"steps-post\")\n",
    "plt.title('Accuracies of regularised Decision Tree depending on Alpha')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Accuracy')\n",
    "#plt.ylim([0,1])\n",
    "plt.legend(loc='lower left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
