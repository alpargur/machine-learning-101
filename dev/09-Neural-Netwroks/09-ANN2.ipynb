{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09 - Artifical neural networks 2\n",
    "\n",
    "The goal of this exercise is to to develop an understanding how to tune the hyperparameter for a simple Artificial neural network using keras and scikit-learn.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "To solve this notebook you need the knowledge from the previous notebook. If you have problems solving it, take another look at the last week's notebooks.\n",
    "    \n",
    "It's also recommended to read the chapter 10 of the book in advance.\n",
    "</div>\n",
    "\n",
    "**Task**: In this exercise, we want to predict the selling price of a used car.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "In this Jupyter-Notebook the hyperparameter tuning decribed in the 2nd edition of Geron's book using the Keras wrapper and RandomizedSearch is used. \n",
    "    Feel free to use the Keras Tuner as in the 3rd edition used. Take the steps described there. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell two import the following modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "%matplotlib inline\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\" align=\"left\">Load and preprocess the data</h2>\n",
    "\n",
    "First, the data must be loaded. In the notebook on regression we have already used this data set. To compare the results, all preprocessing steps are applied again to get the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/car data.csv')\n",
    "dataset = df[['Selling_Price', 'Present_Price', 'Kms_Driven']].copy()\n",
    "dataset['Age'] = 2022 - df['Year']\n",
    "dataset = dataset.join(pd.get_dummies(df[['Fuel_Type','Transmission','Seller_Type']], drop_first=True))\n",
    "dataset_droped = dataset.drop(['Kms_Driven', 'Fuel_Type_Petrol'], axis=1)\n",
    "dataset_droped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the data has been preprocessed, the train-test split can be completed. Since the optimization of the neural network is very sensitive to the scale of the data, the features are first standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_droped.drop('Selling_Price',axis=1)\n",
    "y = dataset_droped['Selling_Price']\n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method can be applied for evaluation of the network's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "def evaulate_model(model, X_test, y_test):\n",
    "    pred_test = model.predict(X_test)\n",
    "    # model metrics\n",
    "    print('R^2 Test:', r2_score(y_test, pred_test))\n",
    "    print('RMSE Test:', np.sqrt(mean_squared_error(y_test, pred_test)))\n",
    "    # residual plot\n",
    "    plt.scatter(pred_test, y_test)\n",
    "    plt.xlabel('Predicted selling price')\n",
    "    plt.ylabel('Actual selling price')\n",
    "    plt.axline((0, 0), slope=1, color=\"black\")\n",
    "    upper_lim = 30\n",
    "    plt.ylim([0,upper_lim])\n",
    "    plt.xlim([0,upper_lim])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\" align=\"left\">Build a Model</h2>\n",
    "\n",
    "In this notebook, we want to use scikit's RandomizedSearch for hyperparameter optimization. For this, a scikit-wrapper method is needed. In the book of Géron `tf.keras.wrappers.scikit_learn` is used for this. This is deprecated in the meantime. Instead, the use of the external package [`scikeras`](https://www.adriangb.com/scikeras/stable/) is recommended. To use it, it must first be installed via *pip*. Since this is a regression task, the KerasRegressor wrapper method must be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a model, the KerasRegressor must be passed a function that creates and returns the model. The parameters of this function can be used later as hyperparmeter. In this case we want to adjust the number of hidden layers and the number of neurons per hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_hidden=1, n_neurons=10): \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=5))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mse\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Task</b><br> \n",
    "Create a KerasRegressor with the parameters below. Then train it with 100 epochs with early stopping on the training dataset. Uses the test dataset for validation. \n",
    "</div>\n",
    "\n",
    "Use this hyperparameters for the KerasRegressor:\n",
    "\n",
    "``` python\n",
    "    n_hidden=1\n",
    "    n_neurons=10\n",
    "    loss='mean_squared_error'\n",
    "    optimizer='sgd'\n",
    "    random_state=42\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "keras_reg = None\n",
    "# Write Your Code Here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaulate_model(keras_reg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\" align=\"left\">Hyperparameter-Tuning</h2>\n",
    "\n",
    "Now we can initialize a RandomizedSearch with the trained scikit wrapper `keras_reg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command shows all parameters which can be set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Task</b><br> \n",
    "Perform a hyperparameter search with the RandomSearchCV on scikit. Use a 3-fold crossvalidation and test at least 10 different parameter sets. To achieve comparable results, use 42 as random_state. Train with at least 100 epochs and use early stopping.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_hidden\": np.arange(1,15),\n",
    "    \"n_neurons\":np.arange(1,200),\n",
    "    \"loss\": [\"mean_squared_error\"],\n",
    "    \"optimizer\": [\"adam\", \"sgd\"],\n",
    "    \"optimizer__learning_rate\": [0.001, 0.01, 0.01]\n",
    "}\n",
    "\n",
    "rs = None\n",
    "# Write Your Code Here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now can recreate the model with the best parameter for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_reg = KerasRegressor(get_model,\n",
    "                         n_hidden=rs.best_params_[\"n_hidden\"],\n",
    "                         n_neurons=rs.best_params_[\"n_neurons\"],\n",
    "                         optimizer=rs.best_params_[\"optimizer\"],\n",
    "                         optimizer__learning_rate=rs.best_params_[\"optimizer__learning_rate\"],\n",
    "                         loss=rs.best_params_[\"loss\"],\n",
    "                         random_state=42)\n",
    "\n",
    "best_reg.fit(X_train, y_train, epochs=200,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=early_stopping_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaulate_model(best_reg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\" align=\"left\">Save the Model</h2>\n",
    "\n",
    "There are two formats you can use to save an entire model to disk: the `TensorFlow SavedModel format`, and the older `Keras H5 format`. Géron's book still uses the outdated format. The recommended format is now SavedModel. It is the default when you use model.save().\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Task</b><br> \n",
    "Use the save() method of keras to save to model to disk using the SavedModel format. You can access the model of the keras \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Your Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The saved model includes:\n",
    "\n",
    "- The model's architecture/config\n",
    "- The model's weight values (which were learned during training)\n",
    "- The model's compilation information (if compile() was called)\n",
    "- The optimizer and its state, if any (this enables you to restart training where you left)\n",
    "\n",
    "For further information have a look at the [documentation](https://www.tensorflow.org/guide/keras/save_and_serialize) of TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
