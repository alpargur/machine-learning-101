{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09 - Artifical neural networks 2\n",
    "\n",
    "The goal of this exercise is to to develop an understanding how to tune the hyperparameter for a simple Artificial neural network using keras and scikit-learn.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "To solve this notebook you need the knowledge from the previous notebook. If you have problems solving it, take another look at the last week's notebooks.\n",
    "    \n",
    "It's also recommended to read the chapter 10 of the book in advance.\n",
    "</div>\n",
    "\n",
    "**Task**: In this exercise, we want to predict the selling price of a used car.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "In this Jupyter-Notebook the hyperparameter tuning decribed in the 2nd edition of Geron's book using the Keras wrapper and RandomizedSearch is used. \n",
    "    Feel free to use the Keras Tuner as in the 3rd edition used. Take the steps described there. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell two import the following modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "%matplotlib inline\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\" align=\"left\">Load and preprocess the data</h2>\n",
    "\n",
    "First, the data must be loaded. In the notebook on regression we have already used this data set. To compare the results, all preprocessing steps are applied again to get the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     Selling_Price  Present_Price  Age  Fuel_Type_Diesel  Transmission_Manual  \\\n0             3.35           5.59    8                 0                    1   \n1             4.75           9.54    9                 1                    1   \n2             7.25           9.85    5                 0                    1   \n3             2.85           4.15   11                 0                    1   \n4             4.60           6.87    8                 1                    1   \n..             ...            ...  ...               ...                  ...   \n296           9.50          11.60    6                 1                    1   \n297           4.00           5.90    7                 0                    1   \n298           3.35          11.00   13                 0                    1   \n299          11.50          12.50    5                 1                    1   \n300           5.30           5.90    6                 0                    1   \n\n     Seller_Type_Individual  \n0                         0  \n1                         0  \n2                         0  \n3                         0  \n4                         0  \n..                      ...  \n296                       0  \n297                       0  \n298                       0  \n299                       0  \n300                       0  \n\n[301 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Selling_Price</th>\n      <th>Present_Price</th>\n      <th>Age</th>\n      <th>Fuel_Type_Diesel</th>\n      <th>Transmission_Manual</th>\n      <th>Seller_Type_Individual</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.35</td>\n      <td>5.59</td>\n      <td>8</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.75</td>\n      <td>9.54</td>\n      <td>9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.25</td>\n      <td>9.85</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.85</td>\n      <td>4.15</td>\n      <td>11</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.60</td>\n      <td>6.87</td>\n      <td>8</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>9.50</td>\n      <td>11.60</td>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>4.00</td>\n      <td>5.90</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>3.35</td>\n      <td>11.00</td>\n      <td>13</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>11.50</td>\n      <td>12.50</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>5.30</td>\n      <td>5.90</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>301 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/car data.csv')\n",
    "dataset = df[['Selling_Price', 'Present_Price', 'Kms_Driven']].copy()\n",
    "dataset['Age'] = 2022 - df['Year']\n",
    "dataset = dataset.join(pd.get_dummies(df[['Fuel_Type','Transmission','Seller_Type']], drop_first=True))\n",
    "dataset_droped = dataset.drop(['Kms_Driven', 'Fuel_Type_Petrol'], axis=1)\n",
    "dataset_droped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the data has been preprocessed, the train-test split can be completed. Since the optimization of the neural network is very sensitive to the scale of the data, the features are first standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((240, 5), (61, 5), (240,), (61,))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset_droped.drop('Selling_Price',axis=1)\n",
    "y = dataset_droped['Selling_Price']\n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method can be applied for evaluation of the network's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "def evaulate_model(model, X_test, y_test):\n",
    "    pred_test = model.predict(X_test)\n",
    "    # model metrics\n",
    "    print('R^2 Test:', r2_score(y_test, pred_test))\n",
    "    print('RMSE Test:', np.sqrt(mean_squared_error(y_test, pred_test)))\n",
    "    # residual plot\n",
    "    plt.scatter(pred_test, y_test)\n",
    "    plt.xlabel('Predicted selling price')\n",
    "    plt.ylabel('Actual selling price')\n",
    "    plt.axline((0, 0), slope=1, color=\"black\")\n",
    "    upper_lim = 30\n",
    "    plt.ylim([0,upper_lim])\n",
    "    plt.xlim([0,upper_lim])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\" align=\"left\">Build a Model</h2>\n",
    "\n",
    "In this notebook, we want to use scikit's RandomizedSearch for hyperparameter optimization. For this, a scikit-wrapper method is needed. In the book of Géron `tf.keras.wrappers.scikit_learn` is used for this. This is deprecated in the meantime. Instead, the use of the external package [`scikeras`](https://www.adriangb.com/scikeras/stable/) is recommended. To use it, it must first be installed via *pip*. Since this is a regression task, the KerasRegressor wrapper method must be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a model, the KerasRegressor must be passed a function that creates and returns the model. The parameters of this function can be used later as hyperparmeter. In this case we want to adjust the number of hidden layers and the number of neurons per hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_hidden=1, n_neurons=10): \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=5))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mse\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Task</b><br> \n",
    "Create a KerasRegressor with the parameters below. Then train it with 100 epochs with early stopping on the training dataset. Uses the test dataset for validation. \n",
    "</div>\n",
    "\n",
    "Use this hyperparameters for the KerasRegressor:\n",
    "\n",
    "``` python\n",
    "    n_hidden=1\n",
    "    n_neurons=10\n",
    "    loss='mean_squared_error'\n",
    "    optimizer='sgd'\n",
    "    random_state=42\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 42.5654 - val_loss: 39.8314\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 41.4087 - val_loss: 38.8238\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 40.4544 - val_loss: 37.9139\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 39.5965 - val_loss: 37.1143\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 38.7914 - val_loss: 36.2604\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 37.9730 - val_loss: 35.4653\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 37.2065 - val_loss: 34.6718\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36.3931 - val_loss: 33.8600\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 35.5995 - val_loss: 33.0594\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 34.7910 - val_loss: 32.1655\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 33.9503 - val_loss: 31.3628\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 33.1711 - val_loss: 30.5955\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 32.4192 - val_loss: 29.7889\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 31.5954 - val_loss: 28.9254\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 30.7868 - val_loss: 28.1942\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 30.0535 - val_loss: 27.4125\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 29.2804 - val_loss: 26.6205\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 28.4781 - val_loss: 25.7873\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27.6800 - val_loss: 25.0110\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 26.9115 - val_loss: 24.2125\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 26.1413 - val_loss: 23.4546\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 25.3760 - val_loss: 22.7039\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 24.6422 - val_loss: 21.9392\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.8651 - val_loss: 21.1376\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23.1139 - val_loss: 20.4404\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 22.4116 - val_loss: 19.7558\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 21.7272 - val_loss: 19.0819\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 21.0228 - val_loss: 18.3278\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20.2821 - val_loss: 17.6483\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 19.5796 - val_loss: 16.9544\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18.9124 - val_loss: 16.3982\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 18.3049 - val_loss: 15.7719\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 17.6487 - val_loss: 15.1236\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 17.0039 - val_loss: 14.5582\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 16.3939 - val_loss: 13.9730\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15.7967 - val_loss: 13.4606\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15.2113 - val_loss: 12.9160\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 14.6021 - val_loss: 12.3727\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 13.9966 - val_loss: 11.8586\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 13.4352 - val_loss: 11.3592\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12.8708 - val_loss: 10.8733\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12.3062 - val_loss: 10.4179\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11.7752 - val_loss: 10.0006\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11.2816 - val_loss: 9.5924\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10.8016 - val_loss: 9.2187\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10.3599 - val_loss: 8.8675\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9.9152 - val_loss: 8.5253\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9.4684 - val_loss: 8.1815\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9.0508 - val_loss: 7.8737\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8.6539 - val_loss: 7.5863\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8.2733 - val_loss: 7.3026\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.9130 - val_loss: 7.0447\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.5554 - val_loss: 6.7776\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.2139 - val_loss: 6.5692\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.9065 - val_loss: 6.3440\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.6060 - val_loss: 6.1748\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.3572 - val_loss: 6.0048\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.1256 - val_loss: 5.8428\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.9070 - val_loss: 5.6830\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.6881 - val_loss: 5.5354\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.4735 - val_loss: 5.4164\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.3063 - val_loss: 5.2938\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.1291 - val_loss: 5.1622\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.9570 - val_loss: 5.0429\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8046 - val_loss: 4.9262\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6675 - val_loss: 4.8156\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5335 - val_loss: 4.7125\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3835 - val_loss: 4.6044\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2638 - val_loss: 4.5068\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1515 - val_loss: 4.3989\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0409 - val_loss: 4.2988\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9337 - val_loss: 4.1955\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8264 - val_loss: 4.0834\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7263 - val_loss: 3.9896\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6255 - val_loss: 3.8940\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5315 - val_loss: 3.7906\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4437 - val_loss: 3.6865\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3543 - val_loss: 3.5919\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2677 - val_loss: 3.5068\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1830 - val_loss: 3.4084\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0985 - val_loss: 3.3184\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0223 - val_loss: 3.2299\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.9529 - val_loss: 3.1431\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.8640 - val_loss: 3.0710\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.8046 - val_loss: 2.9936\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.7341 - val_loss: 2.9048\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.6677 - val_loss: 2.8215\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.6016 - val_loss: 2.7415\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.5485 - val_loss: 2.6684\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.4808 - val_loss: 2.5991\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.4264 - val_loss: 2.5252\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.3652 - val_loss: 2.4640\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.3177 - val_loss: 2.4039\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.2672 - val_loss: 2.3399\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.2158 - val_loss: 2.2832\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.1781 - val_loss: 2.2275\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.1364 - val_loss: 2.1730\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.1010 - val_loss: 2.1190\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.0622 - val_loss: 2.0745\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.0246 - val_loss: 2.0215\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Test score:\t 0.9122451157166211\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "keras_reg = KerasRegressor(get_model())\n",
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data = (X_test, y_test),\n",
    "              callbacks = early_stopping_cb)\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "print('Test score:\\t', mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step\n",
      "R^2 Test: 0.9122451157166211\n",
      "RMSE Test: 1.4217893845355805\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaulate_model(keras_reg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\" align=\"left\">Hyperparameter-Tuning</h2>\n",
    "\n",
    "Now we can initialize a RandomizedSearch with the trained scikit wrapper `keras_reg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command shows all parameters which can be set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs'])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Task</b><br> \n",
    "Perform a hyperparameter search with the RandomSearchCV on scikit. Use a 3-fold crossvalidation and test at least 10 different parameter sets. To achieve comparable results, use 42 as random_state. Train with at least 100 epochs and use early stopping.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO: find out why building of optimizer is failing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://ec0bd1b6047344d388b2c3ea9be633d9/assets\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RMSprop' object has no attribute 'build'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 10>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m params \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn_hidden\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m15\u001B[39m),\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn_neurons\u001B[39m\u001B[38;5;124m\"\u001B[39m:np\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m200\u001B[39m),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moptimizer__learning_rate\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;241m0.001\u001B[39m, \u001B[38;5;241m0.01\u001B[39m, \u001B[38;5;241m0.01\u001B[39m]\n\u001B[1;32m      7\u001B[0m }\n\u001B[1;32m      9\u001B[0m rs \u001B[38;5;241m=\u001B[39m RandomizedSearchCV(keras_reg, params, n_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m \u001B[43mrs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m       \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m       \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mearly_stopping_cb\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:788\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    785\u001B[0m cv_orig \u001B[38;5;241m=\u001B[39m check_cv(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv, y, classifier\u001B[38;5;241m=\u001B[39mis_classifier(estimator))\n\u001B[1;32m    786\u001B[0m n_splits \u001B[38;5;241m=\u001B[39m cv_orig\u001B[38;5;241m.\u001B[39mget_n_splits(X, y, groups)\n\u001B[0;32m--> 788\u001B[0m base_estimator \u001B[38;5;241m=\u001B[39m \u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    790\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs, pre_dispatch\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpre_dispatch)\n\u001B[1;32m    792\u001B[0m fit_and_score_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\n\u001B[1;32m    793\u001B[0m     scorer\u001B[38;5;241m=\u001B[39mscorers,\n\u001B[1;32m    794\u001B[0m     fit_params\u001B[38;5;241m=\u001B[39mfit_params,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    800\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose,\n\u001B[1;32m    801\u001B[0m )\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:89\u001B[0m, in \u001B[0;36mclone\u001B[0;34m(estimator, safe)\u001B[0m\n\u001B[1;32m     87\u001B[0m new_object_params \u001B[38;5;241m=\u001B[39m estimator\u001B[38;5;241m.\u001B[39mget_params(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, param \u001B[38;5;129;01min\u001B[39;00m new_object_params\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m---> 89\u001B[0m     new_object_params[name] \u001B[38;5;241m=\u001B[39m \u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msafe\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     90\u001B[0m new_object \u001B[38;5;241m=\u001B[39m klass(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mnew_object_params)\n\u001B[1;32m     91\u001B[0m params_set \u001B[38;5;241m=\u001B[39m new_object\u001B[38;5;241m.\u001B[39mget_params(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:70\u001B[0m, in \u001B[0;36mclone\u001B[0;34m(estimator, safe)\u001B[0m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(estimator, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mget_params\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(estimator, \u001B[38;5;28mtype\u001B[39m):\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m safe:\n\u001B[0;32m---> 70\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcopy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(estimator, \u001B[38;5;28mtype\u001B[39m):\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.8/copy.py:153\u001B[0m, in \u001B[0;36mdeepcopy\u001B[0;34m(x, memo, _nil)\u001B[0m\n\u001B[1;32m    151\u001B[0m copier \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(x, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__deepcopy__\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copier \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 153\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcopier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmemo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    155\u001B[0m     reductor \u001B[38;5;241m=\u001B[39m dispatch_table\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28mcls\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/scikeras/_saving_utils.py:81\u001B[0m, in \u001B[0;36mdeepcopy_model\u001B[0;34m(model, memo)\u001B[0m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdeepcopy_model\u001B[39m(model: keras\u001B[38;5;241m.\u001B[39mModel, memo: Dict[Hashable, Any]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m keras\u001B[38;5;241m.\u001B[39mModel:\n\u001B[1;32m     80\u001B[0m     _, (model_bytes,) \u001B[38;5;241m=\u001B[39m pack_keras_model(model)\n\u001B[0;32m---> 81\u001B[0m     new_model \u001B[38;5;241m=\u001B[39m \u001B[43munpack_keras_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_bytes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     82\u001B[0m     memo[model] \u001B[38;5;241m=\u001B[39m new_model\n\u001B[1;32m     83\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m new_model\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/scikeras/_saving_utils.py:51\u001B[0m, in \u001B[0;36munpack_keras_model\u001B[0;34m(packed_keras_model)\u001B[0m\n\u001B[1;32m     49\u001B[0m model: keras\u001B[38;5;241m.\u001B[39mModel \u001B[38;5;241m=\u001B[39m load_model(temp_dir)\n\u001B[1;32m     50\u001B[0m model\u001B[38;5;241m.\u001B[39mload_weights(temp_dir)\n\u001B[0;32m---> 51\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild\u001B[49m(model\u001B[38;5;241m.\u001B[39mtrainable_variables)\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py:975\u001B[0m, in \u001B[0;36mOptimizerV2.__getattribute__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    973\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_hyper:\n\u001B[1;32m    974\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_hyper(name)\n\u001B[0;32m--> 975\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py:965\u001B[0m, in \u001B[0;36mOptimizerV2.__getattribute__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    963\u001B[0m \u001B[38;5;124;03m\"\"\"Overridden to support hyperparameter access.\"\"\"\u001B[39;00m\n\u001B[1;32m    964\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 965\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getattribute__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    966\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    967\u001B[0m     \u001B[38;5;66;03m# Needed to avoid infinite recursion with __setattr__.\u001B[39;00m\n\u001B[1;32m    968\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_hyper\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'RMSprop' object has no attribute 'build'"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"n_hidden\": np.arange(1,15),\n",
    "    \"n_neurons\":np.arange(1,200),\n",
    "    \"loss\": [\"mean_squared_error\"],\n",
    "    \"optimizer\": [\"adam\", \"sgd\"],\n",
    "    \"optimizer__learning_rate\": [0.001, 0.01, 0.01]\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(keras_reg, params, n_iter=10, cv=3)\n",
    "rs.fit(X_train, y_train, epoch=100,\n",
    "       validation_data=(X_test, y_test),\n",
    "       callbacks=early_stopping_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now can recreate the model with the best parameter for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_reg = KerasRegressor(get_model,\n",
    "                         n_hidden=rs.best_params_[\"n_hidden\"],\n",
    "                         n_neurons=rs.best_params_[\"n_neurons\"],\n",
    "                         optimizer=rs.best_params_[\"optimizer\"],\n",
    "                         optimizer__learning_rate=rs.best_params_[\"optimizer__learning_rate\"],\n",
    "                         loss=rs.best_params_[\"loss\"],\n",
    "                         random_state=42)\n",
    "\n",
    "best_reg.fit(X_train, y_train, epochs=200,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=early_stopping_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaulate_model(best_reg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\" align=\"left\">Save the Model</h2>\n",
    "\n",
    "There are two formats you can use to save an entire model to disk: the `TensorFlow SavedModel format`, and the older `Keras H5 format`. Géron's book still uses the outdated format. The recommended format is now SavedModel. It is the default when you use model.save().\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Task</b><br> \n",
    "Use the save() method of keras to save to model to disk using the SavedModel format. You can access the model of the keras \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasRegressor' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [13]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mkeras_reg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m()\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'KerasRegressor' object has no attribute 'save'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The saved model includes:\n",
    "\n",
    "- The model's architecture/config\n",
    "- The model's weight values (which were learned during training)\n",
    "- The model's compilation information (if compile() was called)\n",
    "- The optimizer and its state, if any (this enables you to restart training where you left)\n",
    "\n",
    "For further information have a look at the [documentation](https://www.tensorflow.org/guide/keras/save_and_serialize) of TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
