{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 - Artifical neural networks\n",
    "\n",
    "The goal of this exercise is to to develop an understanding how to implement a simple Artificial neural network using keras and tensorflow.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "To solve this notebook you need the knowledge from the previous notebook. If you have problems solving it, take another look at the last week's notebooks.\n",
    "    \n",
    "It's also recommended to read the chapter 10 of the book in advance.\n",
    "</div>\n",
    "\n",
    "**Task**: In this exercise, we use a dataset that we have already used in previous exercises to predict heart attacks in patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell two import the following modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "%matplotlib inline\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\" align=\"left\">Load and preprocess the data</h2>\n",
    "\n",
    "First of all, we need to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset/heart.dat', delim_whitespace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\" align=\"left\">Data preprocessing</h2>\n",
    "\n",
    "Now, we can seperate the features and the target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('target', axis=1)\n",
    "y = dataset['target'].replace([1,2],[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling input and output variables is a critical step in using neural network models.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Task</b><br> \n",
    "Use the StandardScaler to scale the whole data set. Save the results in the Variable X_scaled.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_scaled = []\n",
    "# Write Your Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data set is unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we need to perform the train-test-split. Because of the unblanace data set, we have to perform a stratified train-test-split.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Task</b><br> \n",
    "Use the train_test_split method to perform a stratified train-test split. The ratio between train and test should be 80/20. To get comparable results, please set the random_state option to 42.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = [], [], [], []\n",
    "# Write Your Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> <b>Warning</b><br> \n",
    "If we use neural networks, it is typical to use a validation set in addition to the train and test set. The validation set is used for the model selection as well as for the evaluation of the hyperparameter tuning. The test set is used at the very end for the evaluation of the generalization of the model. Since there are only 270 data points available, we will also validate on the test set, which should be avoided.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\" align=\"left\">Build a Model</h2>\n",
    "\n",
    "After we've preprocessed the data for the ANN, we can create your model.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Task</b><br> \n",
    "Use the Sequential API of keras to create a fully-connected deep neural network.\n",
    "</div>\n",
    "\n",
    "*Hints:*\n",
    "- Use `keras.layers.Flatten` layer as input layer\n",
    "- The input size must correspond to the number of features\n",
    "- Use `keras.layers.Dense` layer with ReLu activiation function as hidden layer\n",
    "- Output layer should be a dense layer with only one neuron\n",
    "- Choose the right activation function for the outplut layer for a binary classification problem\n",
    "- Good results can be achived with four hidden layer and <8000 total parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "# Write Your Code Here\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the creation of the model, it must be compiled.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Task</b><br> \n",
    "Compile your model using model.compile(). We want to use the already created Stochastic Gradient Descent optimizer. Choose the right loss and metrics. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.001)\n",
    "# Write Your Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now just test, if the definition works. \n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Task</b><br> \n",
    "Fit the model to the training data and validate it with the test data. Start with a few epochs. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Your Code Here\n",
    "\n",
    "\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to start the training. \n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Task</b><br> \n",
    "Create a early stopping callback using the pre-defined class keras.callbacks.EarlyStopping. The number of epochs with no improvement after which training will be stopped should be set to 3. Save the callback in the variable early_stopping_cb.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"best_model_until_here.h5\")\n",
    "early_stopping_cb = None\n",
    "# Write Your Code Here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model is trained and validated on the test set. To vizualize the results your can use the history variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "ax.grid(True)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_ylabel('Percentage')\n",
    "ax.set_xlabel('Epoch');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\" align=\"left\">Making predictions</h2>\n",
    "\n",
    "The trained model can now be used to predict some values. For evaluation, we use the data points of the test set for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_output = model.predict(X_test)\n",
    "y_pred_output[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data type of the output depends on the chosen activation function of the last layer in the model. For the evaulation we need a binary value classification result for each data point.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Task</b><br> \n",
    "Find a way to transform the output of your model into a binary array with the classification results. Save the results in the variable y_pred.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "# Write Your Code Here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your can use the following code for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=['no heart attack', 'heart attack']\n",
    "test_accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "ax = sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\", yticklabels=class_names, xticklabels=class_names)\n",
    "ax.set_title(f'Test set (Accuracy: {round(test_accuracy*100, 2)}%)')\n",
    "ax.set_xlabel('Predicted', fontsize=12)\n",
    "ax.set_ylabel('Actual', fontsize=12)\n",
    "ax.set_yticklabels(class_names, va='center')\n",
    "print('Recall Score:', recall_score(y_test, y_pred))\n",
    "print('Precision Score:', precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
